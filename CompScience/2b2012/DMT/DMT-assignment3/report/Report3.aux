\relax 
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\@writefile{toc}{\contentsline {title}{Data Mining Techniques\unskip \ \ignorespaces  Assignment 3}{1}}
\@writefile{toc}{\authcount {1}}
\@writefile{toc}{\contentsline {author}{Jeroen Hofman (jhn343) \ \ \ \ \ John Tyree (jte320) \gdef Vrije Universiteit{Vrije Universiteit}}{1}}
\citation{FIFAranking}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Exploratory Data Analysis}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Example of the data-set.\relax }}{2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:ex}{{1}{2}}
\citation{Sismanis}
\citation{Sismanis}
\@writefile{toc}{\contentsline {section}{\numberline {3}Model}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Ranking}{3}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Stochastic gradient descent method.\relax }}{3}}
\newlabel{alg:1}{{1}{3}}
\citation{FIFAcalc}
\citation{FIFAranking}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The 20 highest ranked countries, according to our model (left) and according to FIFA (right).\relax }}{4}}
\newlabel{fig:rank}{{2}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Probability Density Functions}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Prediction}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Probability density functions including fits for winning, tying and losing a game as seen from the highest ranked player for no home-team (left), the highest ranked being a home-team (middle) and against a home-team (right).\relax }}{6}}
\newlabel{fig:hist}{{3}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Results}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Cross Validation}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Parameter Optimization}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Prediction Confidence}{7}}
\newlabel{fig:ranknolearn}{{4a}{8}}
\newlabel{sub@fig:ranknolearn}{{(a)}{a}}
\newlabel{fig:ranklearn}{{4b}{8}}
\newlabel{sub@fig:ranklearn}{{(b)}{b}}
\newlabel{fig:ranklearn300}{{4c}{8}}
\newlabel{sub@fig:ranklearn300}{{(c)}{c}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Convergence of ranks\relax }}{8}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Constant Learning Rate}}}{8}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Linear Decay Learning Rate}}}{8}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {Iteration until Convergence}}}{8}}
\newlabel{fig:rankconvergence}{{4}{8}}
\newlabel{tab:iter}{{1a}{9}}
\newlabel{sub@tab:iter}{{(a)}{a}}
\newlabel{tab:factor}{{1b}{9}}
\newlabel{sub@tab:factor}{{(b)}{b}}
\newlabel{tab:binwidth}{{1c}{9}}
\newlabel{sub@tab:binwidth}{{(c)}{c}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Cross-validation results for a wide range of model parameters and scoring schemes illustrates that increasing complexity is not always the best choice. In this case, we find that the number of iterations used has a relatively low impact on predictive power. We also see that the All-Or-Nothing approach to prediction out performs the more conservative methods in every single test.\relax }}{9}}
\@writefile{lot}{\contentsline {subtable}{\numberline{(a)}{\ignorespaces {Iteration Count ($\gamma $ = 1.5)}}}{9}}
\@writefile{lot}{\contentsline {subtable}{\numberline{(b)}{\ignorespaces {Factor ($\gamma $) (Iteration Count = 150}}}{9}}
\@writefile{lot}{\contentsline {subtable}{\numberline{(c)}{\ignorespaces {Bin Width (Iteration Count = 150, $\gamma $ = 1.5)}}}{9}}
\newlabel{tab:performance}{{1}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Na\"ive Model}{9}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Scores for the Na\"ive Counting model. In this case, the resulting PDFs prove to be more accurate predictors than in the other two models.\relax }}{9}}
\newlabel{tab:naive}{{2}{9}}
\bibcite{FIFAranking}{1}
\bibcite{FIFAcalc}{2}
\bibcite{Sismanis}{3}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusion}{10}}
